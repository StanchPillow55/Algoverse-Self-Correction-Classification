{
  "experiment_metadata": {
    "start_time": "2025-09-16T10:20:29.943762",
    "datasets": {
      "gsm8k": {
        "type": "math",
        "max_samples": 1000
      },
      "humaneval": {
        "type": "code",
        "max_samples": 164
      },
      "superglue": {
        "type": "reasoning",
        "max_samples": 1000
      },
      "mathbench": {
        "type": "math_advanced",
        "max_samples": 1000
      }
    },
    "models": [
      "gpt-4o-mini",
      "claude-haiku",
      "gpt-4o",
      "claude-sonnet",
      "llama-70b",
      "gpt-4",
      "claude-opus"
    ],
    "max_questions_per_dataset": 1000,
    "max_turns": 3,
    "temperature": 0.2,
    "end_time": "2025-09-16T10:20:29.944865",
    "total_duration_seconds": 4.792213439941406e-05
  },
  "experiments": [
    {
      "experiment_id": "fullscale_gpt-4o-mini_gsm8k_20250916T102029Z",
      "model": "gpt-4o-mini",
      "dataset": "gsm8k",
      "status": "dry_run",
      "max_samples": 1000
    }
  ],
  "cost_tracking": [],
  "summary_statistics": {
    "total_experiments": 1,
    "completed": 0,
    "failed": 1,
    "success_rate": 0.0,
    "total_duration_hours": 1.331170399983724e-08,
    "avg_experiment_duration_minutes": 7.987022399902344e-07
  }
}